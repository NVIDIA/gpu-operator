apiVersion: apps/v1
kind: DaemonSet
metadata:
  labels:
    app: nvidia-driver-daemonset
  name: nvidia-driver-daemonset
  namespace: openshift-sro
  annotations:
    openshift.io/scc: nvidia-driver
spec:
  selector:
    matchLabels:
      app: nvidia-driver-daemonset
  template:
    metadata:
      # Mark this pod as a critical add-on; when enabled, the critical add-on scheduler
      # reserves resources for critical add-on pods so that they can be rescheduled after
      # a failure.  This annotation works in tandem with the toleration below.
      annotations:
        scheduler.alpha.kubernetes.io/critical-pod: ""
      labels:
        app: nvidia-driver-daemonset
    spec:
      tolerations:
      - key: nvidia.com/gpu
        operator: Exists
        effect: NoSchedule
      serviceAccount: nvidia-driver
      serviceAccountName: nvidia-driver
      hostPID: true
      containers:
      - image: quay.io/zvonkok/nvidia-driver:v410.79-KERNEL_FULL_VERSION
        imagePullPolicy: Always
        name: nvidia-driver-ctr
        command: ["nvidia-driver"]
        args: ["init"]
        securityContext:
          privileged: true
          seLinuxOptions:
            level: "s0"
        volumeMounts:
          - name: run-nvidia
            mountPath: /run/nvidia
            mountPropagation: Bidirectional
          - name: config
            mountPath: /etc/containers/oci/hooks.d
          - name: host
            mountPath: /host
      volumes:
        - name: host
          hostPath:
            path: /
        - name: run-nvidia
          hostPath:
            path: /run/nvidia
        - name: config
          configMap:
            name: nvidia-driver
            items:
              - key: oci-nvidia-hook-json
                path: oci-nvidia-hook.json
      nodeSelector:
        feature.node.kubernetes.io/pci-10de.present: "true"
        feature.node.kubernetes.io/kernel-version.full: "KERNEL_FULL_VERSION"
