apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: gpu-feature-discovery
  namespace: "FILLED BY THE OPERATOR"
  labels:
    app: gpu-feature-discovery
    app.kubernetes.io/part-of: nvidia-gpu
spec:
  selector:
    matchLabels:
      app: gpu-feature-discovery
      app.kubernetes.io/part-of: nvidia-gpu
  template:
    metadata:
      labels:
        app: gpu-feature-discovery
        app.kubernetes.io/part-of: nvidia-gpu
    spec:
      nodeSelector:
        nvidia.com/gpu.deploy.gpu-feature-discovery: "true"
      tolerations:
        - key: nvidia.com/gpu
          operator: Exists
          effect: NoSchedule
      priorityClassName: system-node-critical
      serviceAccountName: nvidia-gpu-feature-discovery
      initContainers:
        - name: toolkit-validation
          image: "FILLED BY THE OPERATOR"
          command: ['sh', '-c']
          args: ["until [ -f /run/nvidia/validations/toolkit-ready ]; do echo waiting for nvidia container stack to be setup; sleep 5; done"]
          securityContext:
            privileged: true
          volumeMounts:
            - name: run-nvidia-validations
              mountPath: /run/nvidia/validations
              mountPropagation: HostToContainer
        - name: gpu-feature-discovery-imex-init
          image: "FILLED BY THE OPERATOR"
          command: ["/bin/bash", "-c"]
          args:
            - |
              until [[ -f /run/nvidia/validations/driver-ready ]]
              do
                echo "waiting for the driver validations to be ready..."
                sleep 5
              done
              set -o allexport
              cat /run/nvidia/validations/driver-ready
              . /run/nvidia/validations/driver-ready
              
              IMEX_NODES_CONFIG_FILE=/etc/nvidia-imex/nodes_config.cfg
              if [[ -f /config/${IMEX_NODES_CONFIG_FILE} ]]; then
                echo "Removing cached IMEX nodes config"
                rm -f /config/${IMEX_NODES_CONFIG_FILE}
              fi
              if [[ ! -f ${DRIVER_ROOT_CTR_PATH}/${IMEX_NODES_CONFIG_FILE} ]]; then
                echo "No IMEX nodes config path detected; Skipping"
                exit 0
              fi
              echo "Copying IMEX nodes config"
              mkdir -p $(dirname /config/${IMEX_NODES_CONFIG_FILE})
              cp ${DRIVER_ROOT_CTR_PATH}/${IMEX_NODES_CONFIG_FILE} /config/${IMEX_NODES_CONFIG_FILE}
          securityContext:
            privileged: true
          volumeMounts:
            - name: config
              mountPath: /config
            - name: run-nvidia-validations
              mountPath: /run/nvidia/validations
              mountPropagation: HostToContainer
            - name: host-root
              mountPath: /host/etc
              subPath: etc
              readOnly: true
            - name: driver-install-dir
              mountPath: /driver-root/etc
              subPath: etc
              readOnly: true
        - name: config-manager-init
          image: "FILLED BY THE OPERATOR"
          command: ["config-manager"]
          env:
          - name: ONESHOT
            value: "true"
          - name: KUBECONFIG
            value: ""
          - name: NODE_NAME
            valueFrom:
              fieldRef:
                fieldPath: "spec.nodeName"
          - name: NODE_LABEL
            value: "nvidia.com/device-plugin.config"
          - name: CONFIG_FILE_SRCDIR
            value: "/available-configs"
          - name: CONFIG_FILE_DST
            value: "/config/config.yaml"
          - name: DEFAULT_CONFIG
            value: ""
          - name: SEND_SIGNAL
            value: "false"
          - name: SIGNAL
            value: ""
          - name: PROCESS_TO_SIGNAL
            value: ""
      containers:
        - image: "FILLED BY THE OPERATOR"
          name: gpu-feature-discovery
          command: ["gpu-feature-discovery"]
          env:
            - name: GFD_SLEEP_INTERVAL
              value: 60s
            - name: GFD_FAIL_ON_INIT_ERROR
              value: "true"
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
          volumeMounts:
            - name: output-dir
              mountPath: "/etc/kubernetes/node-feature-discovery/features.d"
            - name: dmi-info-dir
              mountPath: "/sys/class/dmi/id"
              readOnly: true
          securityContext:
            privileged: true
        - image: "FILLED BY THE OPERATOR"
          name: config-manager
          command: ["config-manager"]
          securityContext:
            privileged: true
          env:
          - name: ONESHOT
            value: "false"
          - name: KUBECONFIG
            value: ""
          - name: NODE_NAME
            valueFrom:
              fieldRef:
                fieldPath: "spec.nodeName"
          - name: NODE_LABEL
            value: "nvidia.com/device-plugin.config"
          - name: CONFIG_FILE_SRCDIR
            value: "/available-configs"
          - name: CONFIG_FILE_DST
            value: "/config/config.yaml"
          - name: DEFAULT_CONFIG
            value: ""
          - name: SEND_SIGNAL
            value: "true"
          - name: SIGNAL
            value: "1" # SIGHUP
          - name: PROCESS_TO_SIGNAL
            value: "gpu-feature-discovery"
      volumes:
        - name: output-dir
          hostPath:
            path: "/etc/kubernetes/node-feature-discovery/features.d"
        - name: dmi-info-dir
          hostPath:
            path: "/sys/class/dmi/id"
        - name: run-nvidia-validations
          hostPath:
            path: "/run/nvidia/validations"
            type: DirectoryOrCreate
        - name: host-root
          hostPath:
            path: /
        - name: driver-install-dir
          hostPath:
            path: /run/nvidia/driver
            type: DirectoryOrCreate
